1
00:00:00,140 --> 00:00:09,687
一部の人々が超短期的な見通しを持っているのに、同時にLLMに強化学習を重ねることに強
気なのはなぜか、理解できません。もし私たちが本当に人間のような学習者に近いなら、検証

2
00:00:09,687 --> 00:00:13,096
可能な結果に基づいて訓練するこのアプローチ全体は破滅的です。

3
00:00:15,540 --> 00:00:27,317
現在、各研究所は、学習の途中で様々なスキルをモデルに組み込もうとしています。ウェブブ
ラウザの操作やExcelでの財務モデル構築をモデルに教える強化学習環境を構築する企業

4
00:00:27,317 --> 00:00:30,122
群が、サプライチェーンを形成しています。

5
00:00:30,920 --> 00:00:39,533
さて、これらのモデルがすぐに自律的に現場で学習し、この事前準備が全て無意味になるか、
あるいはそうならないか、その場合はAGIは間近ではないということだ。人間は、仕事で使

6
00:00:39,533 --> 00:00:48,147
う可能性のあるあらゆるソフトウェアを予行演習する必要があるような、特別な訓練段階を経
る必要はない。バロン・ミレッジは、最近書いたブログ記事でこの点について興味深い指摘を

7
00:00:48,147 --> 00:00:48,660
している。

8
00:00:48,720 --> 00:00:58,357
彼が書いているのは、「フロンティアモデルが様々なベンチマークで改善しているのを見る時
、私たちは単に規模の拡大や巧妙なML研究のアイデアだけでなく、これらの正確な能力をタ

9
00:00:58,357 --> 00:01:07,995
ーゲットにした質問を作成し、模範解答や推論を提供する博士号や医師、その他の専門家たち
に支払われる何十億ドルもの費用についても考えるべきだ」ということです。この緊張はロボ

10
00:01:07,995 --> 00:01:10,175
ット工学において最も鮮明に見られます。

11
00:01:10,400 --> 00:01:19,122
根本的に言えば、ロボット工学はハードウェアやデータの問題ではなく、アルゴリズムの問題
です。ほんの少しの訓練で、人間は現在のハードウェアを操作して有用な作業を行う方法を学

12
00:01:19,122 --> 00:01:27,845
べます。ですから、もし人間のような学習者がいれば、ロボット工学は大部分が解決済みの問
題となるでしょう。しかし、そのような学習者がいないという事実が、何千もの異なる家庭に

13
00:01:27,845 --> 00:01:32,830
出向き、皿を片付けたり洗濯物をたたんだりする方法を何百万回も練習する必要を生み出して
いるのです。

14
00:01:32,980 --> 00:01:42,999
さて、今後5年以内にテイクオフすると考えている人々から聞いた反論の一つは、超人的なA
I研究者を構築するために、この厄介なRLをすべて行わなければならなかった、そして、こ

15
00:01:42,999 --> 00:01:50,394
の自動化されたイリヤの100万のコピーが、経験から堅牢で効率的な学習を解決する方法を
見つけ出すことができる、というものです。

16
00:01:50,460 --> 00:01:56,096
これはまるで、あの昔のジョークみたいだ。
「売るたびに赤字だけど、数をこなせば取り戻せる」

17
00:01:56,096 --> 00:02:04,550
どういうわけか、この自動研究者がAGIのアルゴリズムを解明するって言うんだから。
それは人類が半世紀以上も頭を悩ませてきた問題なのに。

18
00:02:04,550 --> 00:02:09,546
子供が持つような基本的な学習能力もないくせに、 これは極めて非現実的だと思う。

19
00:02:09,639 --> 00:02:20,082
それに、たとえそう信じていても、研究室が検証可能な報酬から強化学習にどう取り組んでい
るかを説明していません。イリヤを自動化するのに、コンサルタントのパワポ作成スキルを組

20
00:02:20,082 --> 00:02:21,574
み込む必要はありません。

21
00:02:21,780 --> 00:02:32,965
明らかに、研究所の行動はある世界観を示唆しています。それは、これらのモデルが汎化や実
地学習が苦手なままであり続けるため、経済的に役立つと期待されるスキルを事前に組み込む

22
00:02:32,965 --> 00:02:34,829
必要がある、というものです。

23
00:02:36,220 --> 00:02:45,699
もう一つの反論として、たとえモデルがこれらのスキルを実務で習得できたとしても、各ユー
ザーや各企業ごとに何度も繰り返すよりも、訓練中に一度これらのスキルを組み込む方がはる

24
00:02:45,699 --> 00:02:55,178
かに効率的である、ということが挙げられます。そして、ブラウザやターミナルといった一般
的なツールを流暢に扱えるようにすることは非常に理にかなっています。実際、AGIが持つ

25
00:02:55,178 --> 00:02:59,579
主要な利点の一つは、コピー間で知識を共有する能力がより優れていることなのです。

26
00:02:59,840 --> 00:03:11,217
しかし、多くの仕事に必要な企業や状況に特化したスキルを人々は過小評価しており、AIが
それらを習得する堅牢で効率的な方法が現状ありません。

27
00:03:15,960 --> 00:03:26,474
最近、AI研究者と生物学者との食事会で、その生物学者は長期的な視点を持つ方で、なぜ長
期的な視点を持つのか尋ねてみたんです。すると彼女が言うには、最近の研究室での仕事の一

28
00:03:26,474 --> 00:03:34,861
部は、スライドを見て、その中の点が実際にマクロファージなのか、それともマクロファージ
のように見えるだけなのかを判断することだそうです。

29
00:03:35,460 --> 00:03:44,767
そして、AI研究者は、ご想像の通り、こう答えました。「あのね、画像分類は教科書通りの
ディープラーニングの問題です。これは、私たちがこれらのモデルを訓練できる、まさに得意

30
00:03:44,767 --> 00:03:54,075
分野なんです。」そして、これは非常に興味深いやり取りだと思いました。なぜなら、それが
私と、今後数年で変革的な経済的影響を期待する人々との間の、重要な核心を示していたから

31
00:03:54,075 --> 00:03:54,407
です。

32
00:03:54,500 --> 00:04:02,673
人間の労働者が価値があるのは、まさに彼らの仕事の細かな一つ一つの部分に、面倒なトレー
ニングループを組み込む必要がないからです。

33
00:04:02,740 --> 00:04:14,392
この研究室特有のスライド作成方法に合わせてマクロファージの見た目を識別するカスタム学
習パイプラインを構築し、次の研究室特有のマイクロタスクごとに別の学習ループを作る、と

34
00:04:14,392 --> 00:04:24,241
いうのは、正味生産的ではありません。本当に必要なのは、意味的なフィードバックや自己主
導の経験から学習し、人間のように一般化できるAIなのです。

35
00:04:24,600 --> 00:04:36,608
毎日、判断力、状況認識、そして実務で培われるスキルや文脈を要する百もの業務をこなさな
ければなりません。これらの業務は、人によって異なるだけでなく、同じ人でも日ごとに変化

36
00:04:36,608 --> 00:04:46,473
します。あらかじめ定義されたスキルを組み込むだけで、たった一つの仕事すら自動化できな
いのに、ましてや全ての仕事を自動化するなど不可能です。

37
00:04:46,500 --> 00:04:55,225
実際、人々は、今の延長線上でしか考えていないため、実際のAGIがどれほどすごいものに
なるか、過小評価していると思います。彼らは、サーバー上で何十億もの人間のような知能が

38
00:04:55,225 --> 00:05:03,951
、全ての学習をコピーし統合できることを考えていません。はっきり言いますが、私はこれを
期待しています。つまり、今後10年か20年以内に、実際の脳のような知能が出現すると予

39
00:05:03,951 --> 00:05:06,236
想しています。これはかなりぶっ飛んだ話です。

40
00:05:09,660 --> 00:05:18,351
時々人々は、AIが今、企業全体で広く導入されておらず、コーディング以外の分野で多くの
価値を提供していないのは、テクノロジーが普及するのに時間がかかるからだ、と言うでしょ

41
00:05:18,351 --> 00:05:27,043
う。そして、私はこれは言い訳だと思います。人々はこの言い訳を使って、これらのモデルに
は広範な経済的価値を生み出すために必要な能力が単に不足しているという事実をごまかそう

42
00:05:27,043 --> 00:05:33,251
としているのだと思います。もしこれらのモデルが本当にサーバー上の人間のようなものだっ
たら、驚くほど速く普及するでしょう。

43
00:05:33,320 --> 00:05:44,816
実際、彼らは普通の人間従業員よりも、はるかに簡単に統合・導入できます。彼らは数分であ
なたのSlackやDriveの全てを読み込み、他のAI従業員が持つ全てのスキルを即座

44
00:05:44,816 --> 00:05:56,312
に抽出できます。さらに、人間の採用市場はレモン市場に非常に似ていて、事前に良い人材を
見分けるのが難しく、そして明らかに、悪いと判明した人を雇うのは非常にコストがかかりま

45
00:05:56,312 --> 00:05:56,586
す。

46
00:05:57,240 --> 00:06:08,277
これは、検証済みのAGIモデルの別のインスタンスを立ち上げるだけなら、直面したり心配
したりする必要のない問題です。こういった理由から、人を雇うよりも企業にAI労働力を普

47
00:06:08,277 --> 00:06:14,190
及させる方がはるかに簡単になるだろうと私は予想します。そして、企業は常に人を雇ってい
ます。

48
00:06:14,252 --> 00:06:26,240
もしその能力が本当にAGIレベルだったら、人々はこれらのモデルが生み出すトークンを買
うために、年間何兆ドルも喜んで費やすでしょう。世界中の知識労働者は、年間累計で何十兆

49
00:06:26,240 --> 00:06:35,660
ドルもの賃金を得ています。そして、現在、各研究所がこの数字からかけ離れているのは、モ
デルが人間の知識労働者ほど有能ではないからです。

50
00:06:39,892 --> 00:06:48,994
今、こう思うでしょう、「なぜ基準が、研究室が年間何十兆ドルも稼がねばならない、とね？
つい最近まで人々は、「このモデルは推論できるのか？」と言っていたのに。」

51
00:06:49,052 --> 00:06:59,411
これらのモデルに常識はあるのか？単なるパターン認識なのか？そして明らかに、AI推進派
が懐疑派を批判するのは当然だ。ゴールポストを繰り返し動かすことについて。そしてこれは

52
00:06:59,411 --> 00:07:07,674
多くの場合、公平だ。AIが過去10年で遂げた進歩を過小評価しがちだからだ。しかし、あ
る程度のゴールポストの移動は実際には正当化される。

53
00:07:07,732 --> 00:07:17,298
2020年にジェミニ3を見たら、知識労働の半分は自動化できると確信したでしょう。だか
ら、AGIへのボトルネックだと思っていたものを解決し続けています。

54
00:07:17,472 --> 00:07:27,549
我々には、一般的な理解力、フューショット学習、推論能力を持つモデルがある。それなのに
、まだAGIはない。では、これを見て、合理的な反応とは何か？

55
00:07:27,872 --> 00:07:38,754
これを見て「ああ、実は知能や労働には、以前考えていたよりもはるかに多くのものがあるん
だな」と思うのは、全くもって妥当だと思います。そして、我々は非常に近づいており、多く

56
00:07:38,754 --> 00:07:48,212
の点で、私が以前AGIと定義していたものを過去に超えていますが、モデル企業がAGIに
よって示唆されるような何兆ドルもの収益を上げていないという事実

57
00:07:48,612 --> 00:07:52,280
私の以前のAGIの定義が狭すぎたことが明確になった。

58
00:07:52,612 --> 00:08:01,908
そして、これは今後も続くと予想しています。2030年には、研究機関が私の提唱する継続
学習で大きな進歩を遂げ、モデルは年間数千億ドルの収益を上げているでしょう。しかし、す

59
00:08:01,908 --> 00:08:11,095
べての知的労働が自動化されているわけではないでしょう。そして私はこう言うはずです、「
見てください、私たちは多くの進歩を遂げましたが、まだAGIには到達していません。」

60
00:08:11,112 --> 00:08:20,739
私たちには、こういった他の機能も必要です。これらのモデルにはX、Y、Zの機能が必要で
す。モデルは、人々が予測する短い期間のペースで、ますます目覚ましくなっていますが、よ

61
00:08:20,739 --> 00:08:23,604
り役立つのは、人々が予測する長い期間のペースです。

62
00:08:28,612 --> 00:08:38,550
問うべきだ、何をスケールしているのか？事前学習では、非常に明確で一般的な、損失の改善
傾向があった。複数の桁違いの規模と計算量にわたって。

63
00:08:38,912 --> 00:08:50,139
とはいえ、これはべき乗則に基づいていた。それは指数関数的成長の強さとは裏腹に弱いもの
だ。しかし、人々は、宇宙の物理法則と同じくらい予測可能な事前学習スケーリングの威信を

64
00:08:50,139 --> 00:08:59,763
、検証可能な報酬からの強化学習に関する楽観的な予測を正当化するために利用しようとして
いる。それには、確立された公知の傾向がないにもかかわらずだ。

65
00:08:59,972 --> 00:09:05,869
意欲的な研究者が乏しい公開データから示唆を読み解こうとすると、かなり悲観的な結果にな
る。

66
00:09:06,992 --> 00:09:17,319
例えば、トビー・ボードは素晴らしい投稿をしていて、彼はOシリーズの様々なベンチマーク
間の点を巧みに結びつけています。そして、それは彼に示唆しました。「我々は、単一のGP

67
00:09:17,319 --> 00:09:24,081
Tレベルに匹敵するブーストを与えるために、RL計算の総量で100万倍のスケールアップ
のようなものが必要です。」

68
00:09:27,472 --> 00:09:36,945
人々は、AIモデルがより賢い後継システムを生成するコードを書く「ソフトウェアのみのシ
ンギュラリティ」や、AIが後継機のコンピューティングハードウェアも改善する「ソフトウ

69
00:09:36,945 --> 00:09:46,419
ェアとハードウェアを組み合わせたシンギュラリティ」の可能性について、多くの時間を費や
して議論してきました。しかし、これらのシナリオはすべて、私がAGIのさらなる改善の主

70
00:09:46,419 --> 00:09:49,577
要な推進力となると考える「継続学習」を見落としています。

71
00:09:50,912 --> 00:09:59,898
改めて、人間がどうやって能力を高めるか考えてみてください。それはほとんど、関連分野で
の経験から来ています。会話の中で、バロン・ミレッジ氏がこんな興味深い提案をしました。

72
00:09:59,898 --> 00:10:08,885
未来は、継続的に学習するエージェントのようになるかもしれないと。彼らは皆、外に出て様
々な仕事をこなし、価値を生み出し、そしてその全ての学びをハイブマインドモデルに持ち帰

73
00:10:08,885 --> 00:10:13,806
る。そのモデルが、これらのエージェント全てに対して、ある種のバッチ蒸留を行うというも
のです。

74
00:10:13,832 --> 00:10:24,559
エージェント自体はかなり専門化されており、カーパシーが認知コアと呼んだものに加え、配
備される仕事に関連する知識とスキルを備えています。継続学習の解決は一度きりの単一の成

75
00:10:24,559 --> 00:10:30,178
果ではありません。むしろ、それはインコンテキスト学習を解決するような感覚になるでしょ
う。

76
00:10:30,292 --> 00:10:39,018
さて、GPT-3は2020年に、インコンテキスト学習が非常に強力であることをすでに実
証していました。その、えー、インコンテキスト学習能力は非常に驚くべきもので、GPT-

77
00:10:39,018 --> 00:10:47,745
3の論文のタイトルは「言語モデルは少数ショット学習器である」でした。しかしもちろん、
GPT-3が登場した時にインコンテキスト学習を解決したわけではなく、実際、理解度から

78
00:10:47,745 --> 00:10:50,446
コンテキスト長に至るまで、まだ多くの進歩が必要です。

79
00:10:50,772 --> 00:11:01,731
継続学習でも同様の進展を期待しています。来年、研究所は継続学習と呼ぶものを発表するで
しょうが、それは実際に継続学習への進歩となるでしょう。

80
00:11:01,772 --> 00:11:12,315
しかし、人間レベルの、実地での学習は、解決するまでにさらに5年から10年かかるかもし
れません。だから、継続学習を初めて実現し、ますます広く展開され、高性能になるモデルか

81
00:11:12,315 --> 00:11:22,858
ら、爆発的な進歩があるとは期待していません。もし継続学習が突然完全に解決されたとした
ら、サティアがポッドキャストでこの可能性について尋ねた時に言ったように、それは確かに

82
00:11:22,858 --> 00:11:24,991
ゲームセットマッチになるでしょう。

83
00:11:24,992 --> 00:11:34,116
でも、おそらくそうはならないでしょう。その代わり、どこかの研究室がこの問題に最初の手
がかりを見つけ出し、その機能をいじっているうちに、それがどう実装されたかが明らかにな

84
00:11:34,116 --> 00:11:43,241
り、そして他の研究室がすぐにそのブレークスルーを再現し、少し改善するでしょう。それに
、私は以前からこう思っているのですが、これら全てのモデル企業間の競争はかなり激しいま

85
00:11:43,241 --> 00:11:43,893
まだろうと。

86
00:11:44,352 --> 00:11:55,274
そして、それは、これまでの、チャットのユーザーエンゲージメントや合成データといった、
いわゆるフライホイールの全てが、モデル企業間の競争激化をほとんど軽減していないという

87
00:11:55,274 --> 00:11:56,705
観察に基づいています。

88
00:11:56,912 --> 00:12:06,756
毎月のように、大手3社のモデル企業が表彰台を交代で占め、他の競合もそれほど遅れをとっ
ていません。何らかの力が働いているようで、それは人材の引き抜きか、SFでの噂話か、あ

89
00:12:06,756 --> 00:12:14,373
るいは通常のリバースエンジニアリングかもしれません。これらが、これまで単一のラボが持
っていた独走的な優位性を無効にしてきたのです。

90
00:12:14,912 --> 00:12:23,911
これはdwarkesh.comのブログで最初に公開したエッセイの朗読でした。これから
もたくさんのエッセイを公開していく予定です。面接前に自分の考えを整理するのにとても役

91
00:12:23,911 --> 00:12:28,518
立つと気づきました。最新情報を知りたい方はdwarkesh.comで購読してください
。

92
00:12:28,792 --> 00:12:31,717
それでは、次回のポッドキャストでまたお会いしましょう。ではまた。

